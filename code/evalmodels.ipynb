{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 397,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuIs6RV0e3hF",
        "outputId": "5084410b-71e8-4736-d770-10362ff5df86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "#from base_model import EEGNet, Encoder, Decoder\n",
        "# from utils import count_parameters\n",
        "from numpy.fft import rfft, rfftfreq\n",
        "from scipy.stats import wasserstein_distance\n",
        "# from temp_model_old_17k import EEGNetOld_17k\n",
        "import warnings\n",
        "\n",
        "torch.set_default_dtype(torch.float32)\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = 'cuda'\n",
        "else:\n",
        "    device = 'cpu'\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 398,
      "metadata": {
        "id": "EjZwNYsre3hH"
      },
      "outputs": [],
      "source": [
        "%config InlineBackend.figure_format = 'retina'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 399,
      "metadata": {
        "id": "NrvHMrize3hH"
      },
      "outputs": [],
      "source": [
        "def mse(pred, target):\n",
        "    return np.mean((pred - target) ** 2)\n",
        "\n",
        "def rrmse(pred, target):\n",
        "    return np.sqrt(np.mean((pred - target) ** 2)) / np.sqrt(np.mean(target**2))\n",
        "\n",
        "def srrmse(pred, target):\n",
        "    pred_psd = np.abs(rfft(pred))**2\n",
        "    target_psd = np.abs(rfft(target))**2\n",
        "    return np.sqrt(np.mean((pred_psd - target_psd) ** 2)) / np.sqrt(np.mean(target_psd**2))\n",
        "\n",
        "def relative(pred, target):\n",
        "    return np.mean(np.abs(pred - target) / np.abs(target))\n",
        "\n",
        "def sdr(pred, target):\n",
        "    return np.mean(10*np.log10(np.sum(target**2, axis=-1)/np.sum((pred - target)**2, axis=-1)))\n",
        "\n",
        "def corr(pred, target):\n",
        "    n = len(pred)\n",
        "    corrs = np.zeros(n)\n",
        "    for i in range(n):\n",
        "        corrs[i] = np.corrcoef(pred[i, :], target[i, :])[0, 1]\n",
        "    return np.mean(corrs)\n",
        "\n",
        "def psdErr(pred, target):\n",
        "    n = len(pred)\n",
        "    psdErrs = np.zeros(n)\n",
        "    for i in range(n):\n",
        "        psd_pred = np.abs(rfft(pred[i, :]))**2\n",
        "        psd = np.abs(rfft(target[i, :]))**2\n",
        "        prob_pp = psd_pred / np.sum(psd_pred)\n",
        "        prob_p = psd / np.sum(psd)\n",
        "        kld = np.sum(prob_pp * np.log(prob_pp / prob_p))\n",
        "        psdErrs[i] = kld\n",
        "    return np.mean(psdErrs)\n",
        "\n",
        "def wasserstein(pred, target):\n",
        "    n = len(pred)\n",
        "    wass = np.zeros(n)\n",
        "    for i in range(n):\n",
        "        wass[i] = wasserstein_distance(pred[i, :], target[i, :])\n",
        "    return np.mean(wass)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 473,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "modelpath = 'denoiseEEGMIXED_model_CBAMDROP_lowlronecycle_weighted_nonstd_bnorm_epoch_99.pt'\n",
        "dtype=torch.float32\n",
        "datatype = 'denoisenetmixed'\n",
        "std=False\n",
        "\n",
        "if datatype == 'denoisenet':\n",
        "    raw_train_x = np.load(\"/DATA/arvasudata/datasets/denoisenet/data_15_500/test_input_15_500.npy\").squeeze()\n",
        "    raw_train_y = np.load(\"/DATA/arvasudata/datasets/denoisenet/data_15_500/test_output_15_500.npy\").squeeze()\n",
        "    N = raw_train_x.shape[0]\n",
        "\n",
        "    trainx, testx, trainy, testy = train_test_split(raw_train_x, raw_train_y, test_size=.99, random_state=42)\n",
        "\n",
        "elif datatype == 'denoisenetmixed':\n",
        "    raw_train_x = np.load(\"/DATA/arvasudata/datasets/denoisenet/test_input.npy\").squeeze()\n",
        "    raw_train_y = np.load(\"/DATA/arvasudata/datasets/denoisenet/test_output.npy\").squeeze()\n",
        "    N = raw_train_x.shape[0]\n",
        "\n",
        "    trainx, testx, trainy, testy = train_test_split(raw_train_x, raw_train_y, test_size=.99, random_state=42)\n",
        "\n",
        "elif datatype == 'denoisenetEOG':\n",
        "    raw_train_x = np.load('/DATA/arvasudata/datasets/denoisenet/EOG_EEG_test_input.npy')\n",
        "    raw_train_y = np.load('/DATA/arvasudata/datasets/denoisenet/EOG_EEG_test_output.npy')\n",
        "    N = raw_train_x.shape[0]\n",
        "    trainx, testx, trainy, testy = train_test_split(raw_train_x, raw_train_y, test_size=.99, random_state=42)\n",
        "\n",
        "elif datatype == 'denoisenetEOG55':\n",
        "    raw_train_x = np.load('/DATA/arvasudata/datasets/denoisenet/EOG_EEG_test_input_55.npy')\n",
        "    raw_train_y = np.load('/DATA/arvasudata/datasets/denoisenet/EOG_EEG_test_output_55.npy')\n",
        "    N = raw_train_x.shape[0]\n",
        "    trainx, testx, trainy, testy = train_test_split(raw_train_x, raw_train_y, test_size=.99, random_state=42)\n",
        "\n",
        "elif datatype == 'denoisenetEMG':\n",
        "    raw_train_x = np.load('/DATA/arvasudata/datasets/denoisenet/EMG_EEG_test_input.npy')\n",
        "    raw_train_y = np.load('/DATA/arvasudata/datasets/denoisenet/EMG_EEG_test_output.npy')\n",
        "    N = raw_train_x.shape[0]\n",
        "    trainx, testx, trainy, testy = train_test_split(raw_train_x, raw_train_y, test_size=.99, random_state=42)\n",
        "\n",
        "elif datatype == 'denoisenetEMG55':\n",
        "    raw_train_x = np.load('/DATA/arvasudata/datasets/denoisenet/EMG_EEG_test_input_55.npy')\n",
        "    raw_train_y = np.load('/DATA/arvasudata/datasets/denoisenet/EMG_EEG_test_output_55.npy')\n",
        "    N = raw_train_x.shape[0]\n",
        "    trainx, testx, trainy, testy = train_test_split(raw_train_x, raw_train_y, test_size=.99, random_state=42)\n",
        "\n",
        "elif datatype == 'minisim':\n",
        "    raw_train_x = np.load(\"/DATA/arvasudata/datasets/simulated/minicont_snr_-3_3.npy\").squeeze()\n",
        "    raw_train_y = np.load(\"/DATA/arvasudata/datasets/simulated/minicleans_snr_-3_3.npy\").squeeze()\n",
        "    N = raw_train_x.shape[0]\n",
        "\n",
        "    trainx, testx, trainy, testy = train_test_split(raw_train_x, raw_train_y, test_size=.15, random_state=42)\n",
        "\n",
        "elif datatype == 'bci':\n",
        "    raw_train_y = np.load('/DATA/arvasudata/datasets/BCI4/cleans_BCI_3snr_test.npy')\n",
        "    raw_train_x = np.load('/DATA/arvasudata/datasets/BCI4/conts_BCI_3snr_test.npy')\n",
        "    N = raw_train_x.shape[0]\n",
        "\n",
        "    trainx, testx, trainy, testy = train_test_split(raw_train_x, raw_train_y, test_size=.99, random_state=42)\n",
        "\n",
        "elif datatype == 'sim':\n",
        "    raw_train_x = np.load('/DATA/arvasudata/datasets/simulated/conts_snr_-3_3.npy') \n",
        "    raw_train_y = np.load('/DATA/arvasudata/datasets/simulated/cleans_snr_-3_3.npy')\n",
        "    N = raw_train_x.shape[0]\n",
        "    trainx, testx, trainy, testy = train_test_split(raw_train_x, raw_train_y, test_size=.05, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 484,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1194543"
            ]
          },
          "execution_count": 484,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "raw_train_x = np.load('/DATA/arvasudata/datasets/simulated/conts_snr_-3_3.npy') \n",
        "raw_train_y = np.load('/DATA/arvasudata/datasets/simulated/cleans_snr_-3_3.npy')\n",
        "N = raw_train_x.shape[0]\n",
        "trainx, testx, trainy, testy = train_test_split(raw_train_x, raw_train_y, test_size=.05, random_state=42)\n",
        "\n",
        "np.save('/DATA/arvasudata/datasets/simulated/conts_snr_-3_3_test.npy', testx)\n",
        "np.save('/DATA/arvasudata/datasets/simulated/cleans_snr_-3_3_test.npy', testy)\n",
        "np.save('/DATA/arvasudata/datasets/simulated/conts_snr_-3_3_train.npy', trainx)\n",
        "np.save('/DATA/arvasudata/datasets/simulated/cleans_snr_-3_3_train.npy', trainy)\n",
        "N"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 474,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 863
        },
        "id": "gOQz4nb_e3hH",
        "outputId": "4d242d2a-255b-465e-f0da-dca702b8b20c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([7920, 1, 512]) (7920, 1, 512) (7920, 1, 512)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# raw_train_x = np.load(\"/DATA/arvasudata/datasets/denoisenet/data_15_500/test_input_15_500.npy\").squeeze()\n",
        "# raw_train_y = np.load(\"/DATA/arvasudata/datasets/denoisenet/data_15_500/test_output_15_500.npy\").squeeze()\n",
        "\n",
        "trainx = torch.tensor(trainx.reshape(-1, 1, 512), dtype=dtype)\n",
        "testx = torch.tensor(testx.reshape(-1, 1, 512), dtype=dtype).to(device)\n",
        "trainy = torch.tensor(trainy.reshape(-1, 1, 512), dtype=dtype)\n",
        "testy = torch.tensor(testy.reshape(-1, 1, 512), dtype=dtype)\n",
        "\n",
        "arty = testx.cpu() - testy\n",
        "\n",
        "def standardize(x):\n",
        "    # z-score\n",
        "    s = x.std(dim=2, keepdim=True)\n",
        "\n",
        "    s[s == 0] = 1\n",
        "\n",
        "    return (x - x.mean(dim=2, keepdim=True)) / s\n",
        "\n",
        "def mean_center(x):\n",
        "        return x - x.mean(dim=2, keepdim=True)\n",
        "\n",
        "if std:\n",
        "    print('standardised')\n",
        "    #trainx = standardize(trainx)\n",
        "    testx = standardize(testx)\n",
        "    #trainy = standardize(trainy)\n",
        "    testy = standardize(testy)\n",
        "testy = testy.numpy()\n",
        "arty = arty.numpy()\n",
        "\n",
        "print(testx.shape, testy.shape, arty.shape)\n",
        "\n",
        "# idx = 3400\n",
        "\n",
        "# plt.figure()\n",
        "# plt.plot(testx[idx, 0, :].cpu().numpy().squeeze(), label='Input')\n",
        "# plt.plot(testy[idx, 0, :], label='Target')\n",
        "# plt.legend()\n",
        "# plt.show()\n",
        "\n",
        "# plt.figure()\n",
        "# plt.plot(testx[idx, 0, :].cpu().numpy().squeeze()-testy[idx, 0, :].squeeze(), label='Noise', color='green')\n",
        "# plt.legend()\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afyGK_sze3hI"
      },
      "outputs": [],
      "source": [
        "def evalAllMetrics(model, testx, testy, typ='eeg'):\n",
        "    model.eval()\n",
        "\n",
        "    if typ == 'eeg':\n",
        "        idx = 0\n",
        "    elif typ == 'art':\n",
        "        idx = 1\n",
        "\n",
        "    with torch.no_grad():\n",
        "        pred = model(testx)\n",
        "        # pred_art = pred[idx].cpu().numpy().squeeze()\n",
        "        # pred = testx.cpu().numpy().squeeze() - pred_art\n",
        "        pred = pred[idx].cpu().numpy().squeeze()\n",
        "        print(f'{pred.shape}, {testy.shape}')\n",
        "        mse_val = mse(pred, testy)\n",
        "        rel_val = relative(pred, testy)\n",
        "        sdr_val = sdr(pred, testy)\n",
        "        corr_val = corr(pred, testy)\n",
        "        psd_val = psdErr(pred, testy)\n",
        "        wass_val = wasserstein(pred, testy)\n",
        "        rrmse_val = rrmse(pred, testy)\n",
        "        srrmse_val = srrmse(pred, testy)\n",
        "    print(f'MSE:                {mse_val:.4f}')\n",
        "    print(f'RMSE:               {np.sqrt(mse_val):.4f}')\n",
        "    print(f'RRMSE:              {rrmse_val:.4f}')\n",
        "    print(f'SRRMSE:             {srrmse_val:.4f}')\n",
        "    print(f'SDR:                {sdr_val:.4f} dB')\n",
        "    print(f'Correlation:        {corr_val:.4f}')\n",
        "    print(f'PSD KLD:            {psd_val:.4f}')\n",
        "    print(f'PSD Wasserstein:    {wass_val:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 476,
      "metadata": {
        "id": "NryYo3qvn4wR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy.fft import rfft, rfftfreq\n",
        "import torch\n",
        "from torch.nn import Module\n",
        "from torch import nn\n",
        "import ptwt\n",
        "from tslearn.metrics import SoftDTWLossPyTorch\n",
        "\n",
        "class Decoder(Module):\n",
        "    def __init__(self):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.post_latent3 = nn.Sequential(\n",
        "            # in - 128x8, out - 128x16\n",
        "            nn.ConvTranspose1d(128, 128, kernel_size=4, stride=2, padding=1, groups=16),\n",
        "            nn.LeakyReLU()\n",
        "        )\n",
        "\n",
        "        self.post_latent2 = nn.Sequential(\n",
        "            # in - 256x16 (after cat), out - 64x32\n",
        "            nn.Conv1d(256, 128, kernel_size=3, stride=1, padding=1, padding_mode='reflect', groups=64),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.ConvTranspose1d(128, 64, kernel_size=6, stride=2, padding=2, groups=32),\n",
        "            nn.LeakyReLU()\n",
        "        )\n",
        "\n",
        "        self.post_latent1 = nn.Sequential(\n",
        "            # in - 128x32 (after cat), out - 32x64\n",
        "            nn.Conv1d(128, 64, kernel_size=5, stride=1, padding=2, padding_mode='reflect', groups=32),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.ConvTranspose1d(64, 32, kernel_size=6, stride=2, padding=2, groups=16),\n",
        "            nn.LeakyReLU()\n",
        "        )\n",
        "\n",
        "        self.HP_inverse = nn.Sequential(\n",
        "            # in - 32x64 (after cat), out - 1x257\n",
        "            nn.Conv1d(32, 16, kernel_size=5, stride=1, padding=2, padding_mode='reflect', groups=8),  # 16x64\n",
        "            nn.LeakyReLU(),\n",
        "            nn.ConvTranspose1d(16, 8, kernel_size=4, stride=2, padding=4, dilation=3, groups=4),  # 8x128\n",
        "            nn.LeakyReLU(),\n",
        "            nn.ConvTranspose1d(8, 4, kernel_size=3, stride=2, padding=3, dilation=4),    # 4x257\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Conv1d(4, 1, kernel_size=3, stride=1, padding=1, padding_mode='reflect'), # 1x257\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "        self.LP_inverse = nn.Sequential(\n",
        "            # in - 32x64 (after cat), out - 1x257\n",
        "            nn.Conv1d(32, 16, kernel_size=5, stride=1, padding=2, padding_mode='reflect', groups=8),  # 16x64\n",
        "            nn.LeakyReLU(),\n",
        "            nn.ConvTranspose1d(16, 8, kernel_size=10, stride=2, padding=4, groups=4),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.ConvTranspose1d(8, 4, kernel_size=9, stride=2, padding=3, groups=2),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.ConvTranspose1d(4, 1, kernel_size=3, stride=1, padding=1),   # 1x257\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "        self.lp_compress = nn.Conv1d(2, 1, kernel_size=7, stride=1, padding=3, padding_mode='reflect')\n",
        "        self.hp_compress = nn.Conv1d(2, 1, kernel_size=3, stride=1, padding=1, padding_mode='reflect')\n",
        "\n",
        "        self.dwt_conv_inverse = nn.Sequential(\n",
        "            # in - 2x257, out - 1x512 (hopefully)\n",
        "            nn.ConvTranspose1d(2, 16, kernel_size=12, stride=2, padding=6),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Conv1d(16, 1, kernel_size=3, stride=1, padding=1, padding_mode='reflect')\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x, skip_states):\n",
        "        # pre-latent\n",
        "        x = self.post_latent3(x)\n",
        "        # print(f'post_latent3: {x.shape}')\n",
        "\n",
        "        x = torch.cat((x, skip_states[-1]), dim=1)\n",
        "        x = self.post_latent2(x)\n",
        "        # print(f'post_latent2: {x.shape}')\n",
        "\n",
        "        x = torch.cat((x, skip_states[-2]), dim=1)\n",
        "        x = self.post_latent1(x)\n",
        "        # print(f'post_latent1: {x.shape}')\n",
        "\n",
        "        # split 32x64 into lp and hp\n",
        "        # should use torch.split()? is that faster?\n",
        "        lpi, hpi = torch.split(x, 16, dim=1)\n",
        "        lp, hp = skip_states[-3]\n",
        "\n",
        "        lp = torch.cat((lp, lpi), dim=1)\n",
        "        hp = torch.cat((hp, hpi), dim=1)\n",
        "\n",
        "        lp = self.LP_inverse(lp)\n",
        "        hp = self.HP_inverse(hp)\n",
        "        # print(f'lp: {lp.shape}, hp: {hp.shape}')\n",
        "\n",
        "        lp_orig, hp_orig = torch.split(skip_states[-4], 1, dim=1)\n",
        "        lp = torch.concat((lp, lp_orig), dim=1)\n",
        "        hp = torch.concat((hp, hp_orig), dim=1)\n",
        "\n",
        "        lp = self.lp_compress(lp)\n",
        "        hp = self.hp_compress(hp)\n",
        "        # print(f'lp_compress: {lp.shape}, hp_compress: {hp.shape}')\n",
        "\n",
        "        x = torch.concat((lp, hp), dim=1)\n",
        "\n",
        "        x = self.dwt_conv_inverse(x)\n",
        "        # print(f'dwt_conv_inverse: {x.shape}')\n",
        "\n",
        "        return x\n",
        "\n",
        "class Encoder(Module):\n",
        "    def __init__(self, wavelet='db2'):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.wavelet = wavelet\n",
        "\n",
        "        self.skip_states = []\n",
        "\n",
        "        self.dwt_conv = nn.Sequential(\n",
        "            # low freq so large kernel and stride\n",
        "            # in - 1x512, out - 2x257\n",
        "            nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1, padding_mode='reflect'),\n",
        "            nn.Conv1d(16, 2, kernel_size=12, stride=2, padding=6, padding_mode='reflect')\n",
        "        )\n",
        "        self.LP_conv_dws = nn.Sequential(\n",
        "            # low freq conv pipeline - depth-wise separable\n",
        "            # in - 2x257, out - 16x64\n",
        "\n",
        "            # first bring up channels\n",
        "            nn.Conv1d(1, 4, kernel_size=3, stride=1, padding=1, padding_mode='reflect'),\n",
        "\n",
        "            # adding groups arg makes it depth-wise separable\n",
        "            nn.Conv1d(4, 8, kernel_size=9, stride=2, padding=3, padding_mode='reflect', groups=2),\n",
        "            nn.Conv1d(8, 16, kernel_size=10, stride=2, padding=4, padding_mode='reflect', groups=4)\n",
        "\n",
        "            # should be N x 16 x 64 at this point\n",
        "        )\n",
        "\n",
        "        # why are we using dilation for high frequency?\n",
        "        self.HP_conv = nn.Sequential(\n",
        "            nn.Conv1d(1, 4, kernel_size=3, stride=1, padding=1, padding_mode='reflect'),\n",
        "\n",
        "            # dilation 4\n",
        "            nn.Conv1d(4, 8, kernel_size=3, stride=2, padding=3, dilation=4, padding_mode='reflect'),\n",
        "            nn.Conv1d(8, 16, kernel_size=4, stride=2, padding=4, dilation=3, padding_mode='reflect')\n",
        "\n",
        "            # N x 16 x 64\n",
        "        )\n",
        "\n",
        "        # change pre-latent to increase depth while decreasing length\n",
        "        # change LP and HP final depths\n",
        "        # can later increase to 2 convs per depth level\n",
        "\n",
        "        self.pre_latent1 = nn.Sequential(\n",
        "            # do some conv and then bring to two channels\n",
        "            # can do dws to reduce params\n",
        "            # in - 32x64, out - 64x32\n",
        "            nn.Conv1d(32, 64, kernel_size=5, stride=2, padding=2, padding_mode='reflect', groups=8),\n",
        "            nn.LeakyReLU(),\n",
        "        )\n",
        "        self.pre_latent2 = nn.Sequential(\n",
        "            # in - 64x32, out - 128x16\n",
        "            nn.Conv1d(64, 128, kernel_size=5, stride=2, padding=2, padding_mode='reflect', groups=16),\n",
        "            nn.LeakyReLU(),\n",
        "        )\n",
        "        self.pre_latent3 = nn.Sequential(\n",
        "            # in - 128x16, out - 256x8\n",
        "            nn.Conv1d(128, 256, kernel_size=3, stride=2, padding=1, padding_mode='reflect', groups=32),\n",
        "            nn.LeakyReLU(),\n",
        "        )\n",
        "\n",
        "    def standardize(self, x):\n",
        "        # z-score\n",
        "        return (x - x.mean())/x.std()\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.skip_states = []\n",
        "        x = self.dwt_conv(x)\n",
        "        x = self.standardize(x)\n",
        "        dwtx = x.clone()\n",
        "        # print(f'dwt shape: {x.shape}')\n",
        "        self.skip_states.append(dwtx)\n",
        "\n",
        "        # lp/hp conv\n",
        "        lp, hp = torch.split(x, 1, dim=1)\n",
        "\n",
        "        lp = self.LP_conv_dws(lp)\n",
        "        hp = self.HP_conv(hp)\n",
        "        # print(f'lp shape: {lp.shape}, hp shape: {hp.shape}')\n",
        "        self.skip_states.append((lp.clone(), hp.clone()))\n",
        "\n",
        "        # concat\n",
        "        x = torch.cat((lp, hp), dim=1)\n",
        "\n",
        "        # pre-latent\n",
        "        x = self.pre_latent1(x)\n",
        "        # print(f'pre-latent1 shape: {x.shape}')\n",
        "        self.skip_states.append(x.clone())\n",
        "        x = self.pre_latent2(x)\n",
        "        # print(f'pre-latent2 shape: {x.shape}')\n",
        "        self.skip_states.append(x.clone())\n",
        "        x = self.pre_latent3(x)\n",
        "        # print(f'pre-latent3 shape: {x.shape}')\n",
        "\n",
        "        eeg, artefact = torch.split(x, 128, dim=1)\n",
        "        # print(f'eeg shape: {eeg.shape}, artefact shape: {artefact.shape}')\n",
        "        return eeg, artefact, dwtx\n",
        "\n",
        "class EEGNet(Module):\n",
        "    def __init__(self, wavelet='db2', dws=True, gamma=0.1, waveletWeight=0.1):\n",
        "        super(EEGNet, self).__init__()\n",
        "        self.encoder = Encoder(wavelet=wavelet)\n",
        "        self.eeg_decoder = Decoder()\n",
        "        self.art_decoder = Decoder()\n",
        "\n",
        "        self.gamma = gamma\n",
        "        self.w = waveletWeight\n",
        "        self.dtwLoss = SoftDTWLossPyTorch(gamma=self.gamma)\n",
        "\n",
        "    def standardize(self, x):\n",
        "        # z-score\n",
        "        return (x - x.mean())/x.std()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # verify that skip states are being passed correctly.\n",
        "        x_inp = x.clone()\n",
        "        eeg_z, artefact_z, dwtx = self.encoder(x)\n",
        "        # print(len(self.encoder.skip_states))\n",
        "        eeg = self.eeg_decoder(eeg_z, self.encoder.skip_states)\n",
        "        artefact = self.art_decoder(artefact_z, self.encoder.skip_states)\n",
        "\n",
        "        return eeg, artefact, eeg_z, artefact_z, dwtx, x_inp\n",
        "\n",
        "    def reconstructionLoss(self, x, y):\n",
        "        return self.dtwLoss(x, y).mean()\n",
        "\n",
        "    def mutualInfoLoss(self):\n",
        "        # multiply by a small scaling factor, because MI loss will encourage x = constant\n",
        "        return 0\n",
        "\n",
        "    def waveletLoss(self, x, cA, cD):\n",
        "        assert x.shape[1] == 2, f\"dwt_conv should output 2 channels (LP and HP). current shape: {x.shape}\"\n",
        "        loss = nn.L1Loss()\n",
        "        return loss(x[:, 0, :].squeeze(), cA.squeeze()) + loss(x[:, 1, :].squeeze(), cD.squeeze())\n",
        "\n",
        "    def loss(self, f, eeg_y, artefact_y):\n",
        "        # time this, tuple unpacking can be slow\n",
        "        eeg, artefact, eeg_z, artefact_z, dwtx, x_inp = f\n",
        "        cA, cD = self.dwt(x_inp, wavelet=self.encoder.wavelet)\n",
        "        eegrec = self.reconstructionLoss(eeg, eeg_y)\n",
        "        artefactrec = self.reconstructionLoss(artefact, artefact_y)\n",
        "        mim = self.mutualInfoLoss()\n",
        "        wvl = self.waveletLoss(dwtx, cA, cD)\n",
        "        # print(f'mag test. eegrec: {eegrec}, artefactrec: {artefactrec}, mim: {mim}, wvl: {wvl}')\n",
        "        return eegrec + artefactrec + mim + self.w*wvl\n",
        "\n",
        "    def dwt(self, x, wavelet='db2'):\n",
        "        # cA is low, cD is high\n",
        "        # question - which signal extension mode to use?\n",
        "        # question/idead - since LP is very close to original signal (maybe because we're using EOG)\n",
        "        # we can try pyramid DWT and use second order LP and HP, or even all 3.\n",
        "        # could define custom wavelet according to frequency bands preference\n",
        "\n",
        "        cA, cD = ptwt.wavedec(x, wavelet, level=1)\n",
        "        # print(f'inside dwt, x - {x.shape}, cA - {cA.shape}, cD - {cD.shape}')\n",
        "        return cA, cD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 477,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLYW9IvHp-RJ",
        "outputId": "c3b1ec77-289f-4b7f-faf7-d060fc9268c9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([7920, 1, 512]), (7920, 1, 512))"
            ]
          },
          "execution_count": 477,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "testx.shape, testy.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 478,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "VQ9XiNWNe3hI",
        "outputId": "f841551a-41cb-4f70-8b66-f352a8bc16b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([7920, 1, 512]) (7920, 1, 512) (7920, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_3763144/2602077927.py:4: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  art = testx.cpu()-testy\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(7920, 512), (7920, 512)\n",
            "MSE:                0.0532\n",
            "RMSE:               0.2306\n",
            "RRMSE:              0.4168\n",
            "SRRMSE:             0.4043\n",
            "SDR:                7.0432 dB\n",
            "Correlation:        0.8728\n",
            "PSD KLD:            0.2301\n",
            "PSD Wasserstein:    0.0621\n"
          ]
        }
      ],
      "source": [
        "model = torch.load(f'{modelpath}', weights_only=False, map_location='cpu')\n",
        "model.to('cpu')\n",
        "model.eval()\n",
        "art = testx.cpu()-testy\n",
        "art = art[:, 0, :].numpy()\n",
        "print(testx.shape, testy.shape, art.shape)\n",
        "# model.to(device)\n",
        "with torch.no_grad():\n",
        "    evalAllMetrics(model, testx.to('cpu'), testy[:, 0, :], typ='eeg')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "denoise",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
